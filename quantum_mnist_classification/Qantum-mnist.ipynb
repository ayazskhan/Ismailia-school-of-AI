{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5zajCphfSmQ",
        "colab_type": "code",
        "outputId": "114678a2-2f9b-4d0e-bb44-e461d31b86e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install git+https://github.com/kareem1925/pennylane-qulacs@GPU_support"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/kareem1925/pennylane-qulacs@GPU_support\n",
            "  Cloning https://github.com/kareem1925/pennylane-qulacs (to revision GPU_support) to /tmp/pip-req-build-e91pfoda\n",
            "  Running command git clone -q https://github.com/kareem1925/pennylane-qulacs /tmp/pip-req-build-e91pfoda\n",
            "  Running command git checkout -b GPU_support --track origin/GPU_support\n",
            "  Switched to a new branch 'GPU_support'\n",
            "  Branch 'GPU_support' set up to track remote branch 'GPU_support' from 'origin'.\n",
            "Collecting pennylane>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/56/149f6bf2ec07712821295611172815b8a93bc2dc0485a65282924c194b96/PennyLane-0.7.0-py3-none-any.whl (155kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pennylane-qulacs==0.0.4) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pennylane-qulacs==0.0.4) (1.4.1)\n",
            "Collecting qulacs-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/59/cb6505707bfc76a8d4a039dc779fc3de70a6b5428a4016423a5b072422f1/Qulacs-GPU-0.1.9.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 9.0MB/s \n",
            "\u001b[?25hCollecting semantic-version==2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Collecting toml\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pennylane>=0.5.0->pennylane-qulacs==0.0.4) (2.4)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.6/dist-packages (from pennylane>=0.5.0->pennylane-qulacs==0.0.4) (1.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pennylane>=0.5.0->pennylane-qulacs==0.0.4) (4.4.1)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd->pennylane>=0.5.0->pennylane-qulacs==0.0.4) (0.16.0)\n",
            "Building wheels for collected packages: pennylane-qulacs, qulacs-gpu\n",
            "  Building wheel for pennylane-qulacs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pennylane-qulacs: filename=pennylane_qulacs-0.0.4-cp36-none-any.whl size=4564 sha256=29f57de6b1b035552950e72006ea9bdd663e87f045b04350e9dc97d29b99b2fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tfvt2amk/wheels/93/58/04/19f31c7d05f27562d0941ae63f8c34e73620017d13840d4d00\n",
            "  Building wheel for qulacs-gpu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qulacs-gpu: filename=Qulacs_GPU-0.1.9-cp36-cp36m-linux_x86_64.whl size=839889 sha256=bdc4814b28022d246c749d19ab34b3806dcf7c3ae890962a997c7c419ea3f572\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/57/aa/800e4bdd8dfc7514f5c5a15e58e232f26f5ca481063dd2a4ef\n",
            "Successfully built pennylane-qulacs qulacs-gpu\n",
            "Installing collected packages: semantic-version, toml, appdirs, pennylane, qulacs-gpu, pennylane-qulacs\n",
            "  Found existing installation: semantic-version 2.8.4\n",
            "    Uninstalling semantic-version-2.8.4:\n",
            "      Successfully uninstalled semantic-version-2.8.4\n",
            "Successfully installed appdirs-1.4.3 pennylane-0.7.0 pennylane-qulacs-0.0.4 qulacs-gpu-0.1.9 semantic-version-2.6.0 toml-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIgxDQKJhe45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfhsYF95hgZv",
        "colab_type": "code",
        "outputId": "04ac781d-f005-492a-8060-2ef93e0f74b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import qulacs\n",
        "qulacs.QuantumStateGpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "qulacs.QuantumStateGpu"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNpZ1AbZxuJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pennylane import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def _weighted_sum(sample_score, sample_weight, normalize=False):\n",
        "    if normalize:\n",
        "        return np.average(sample_score, weights=sample_weight)\n",
        "    elif sample_weight is not None:\n",
        "        return np.dot(sample_score, sample_weight)\n",
        "    else:\n",
        "        return sample_score.sum()\n",
        "\n",
        "\n",
        "def log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None,\n",
        "             labels=None):\n",
        "    \n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "\n",
        "    if labels is not None:\n",
        "        lb.fit(labels)\n",
        "    else:\n",
        "        lb.fit(y_true)\n",
        "\n",
        "    if len(lb.classes_) == 1:\n",
        "        if labels is None:\n",
        "            raise ValueError('y_true contains only one label ({0}). Please '\n",
        "                             'provide the true labels explicitly through the '\n",
        "                             'labels argument.'.format(lb.classes_[0]))\n",
        "        else:\n",
        "            raise ValueError('The labels array needs to contain at least two '\n",
        "                             'labels for log_loss, '\n",
        "                             'got {0}.'.format(lb.classes_))\n",
        "\n",
        "    transformed_labels = lb.transform(y_true)\n",
        "\n",
        "    if transformed_labels.shape[1] == 1:\n",
        "        transformed_labels = np.append(1 - transformed_labels,\n",
        "                                       transformed_labels, axis=1)\n",
        "\n",
        "    # Clipping\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "\n",
        "    # If y_pred is of single dimension, assume y_true to be binary\n",
        "    # and then check.\n",
        "    if y_pred.ndim == 1:\n",
        "        y_pred = y_pred[:, np.newaxis]\n",
        "    if y_pred.shape[1] == 1:\n",
        "        y_pred = np.append(1 - y_pred, y_pred, axis=1)\n",
        "\n",
        "    # Check if dimensions are consistent.\n",
        "#    transformed_labels = check_array(transformed_labels)\n",
        "    if len(lb.classes_) != y_pred.shape[1]:\n",
        "        if labels is None:\n",
        "            raise ValueError(\"y_true and y_pred contain different number of \"\n",
        "                             \"classes {0}, {1}. Please provide the true \"\n",
        "                             \"labels explicitly through the labels argument. \"\n",
        "                             \"Classes found in \"\n",
        "                             \"y_true: {2}\".format(transformed_labels.shape[1],\n",
        "                                                  y_pred.shape[1],\n",
        "                                                  lb.classes_))\n",
        "        else:\n",
        "            raise ValueError('The number of classes in labels is different '\n",
        "                             'from that in y_pred. Classes found in '\n",
        "                             'labels: {0}'.format(lb.classes_))\n",
        "\n",
        "    # Renormalize\n",
        "    y_pred /= y_pred.sum(axis=1)[:, np.newaxis]\n",
        "    loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
        "#    print(loss)\n",
        "\n",
        "    return loss\n",
        "from sklearn.metrics import balanced_accuracy_score as acc\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    \"\"\"Accuracy score.\n",
        "\n",
        "    Args:\n",
        "        y_true (array[float]): 1-d array of targets\n",
        "        y_predicted (array[float]): 1-d array of predictions\n",
        "        state_labels (array[float]): 1-d array of state representations for labels\n",
        "\n",
        "    Returns:\n",
        "        score (float): the fraction of correctly classified samples\n",
        "    \"\"\"\n",
        "    weights = compute_sample_weight('balanced',y_true)\n",
        "\n",
        "    return acc(y_true,y_pred,sample_weight=weights)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2s_IWoDhlSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pennylane import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import compute_sample_weight\n",
        "import pennylane as qml\n",
        "from sklearn.datasets import load_digits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUXWybtEh_5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac63c70c-644f-413d-d5da-0bcef8075cf0"
      },
      "source": [
        "X,y = load_digits(n_class=2,return_X_y=True)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=5,stratify=y)\n",
        "y_train = np.array([-1 if i==0 else i for i in y_train])\n",
        "#y_train = np.array([0 if i==1 else i for i in y_train])\n",
        "#y_train = np.array([1 if i==2 else i for i in y_train])\n",
        "\n",
        "y_test = np.array([-1 if i==0 else i for i in y_test])\n",
        "#y_test = np.array([0 if i==1 else i for i in y_test])\n",
        "#y_test = np.array([1 if i==2 else i for i in y_test])\n",
        "(y_train==-1).sum()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQB5JG2nwWv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = qml.device(\"qulacs.simulator\", wires=7,shots=1000,analytic = True)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qcircuit(params, X=None):\n",
        "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
        "\n",
        "    Args:\n",
        "        params (array[float]): array of parameters\n",
        "        x (array[float]): single input vector\n",
        "        y (array[float]): single output state density matrix\n",
        "\n",
        "    Returns:\n",
        "        float: fidelity between output state and input\n",
        "    \"\"\"\n",
        "\n",
        "    X = np.hstack((X,X))\n",
        "    qml.templates.AmplitudeEmbedding(X,wires=list(range(7)),pad=0.0,normalize=True,)\n",
        "\n",
        "\n",
        "    qml.templates.StronglyEntanglingLayers(params,wires=list(range(7)))\n",
        "  \n",
        "    \n",
        "            \n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj-Ofcr1wbzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(params, x, y):\n",
        "    \"\"\"Cost function to be minimized.\n",
        "\n",
        "    Args:\n",
        "        params (array[float]): array of parameters\n",
        "        x (array[float]): 2-d array of input vectors\n",
        "        y (array[float]): 1-d array of targets\n",
        "    Returns:\n",
        "        float: loss value to be minimized\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute prediction for each input in data batch\n",
        "    loss = []\n",
        "    pred = []\n",
        "    margin = 0.3\n",
        "    bias = params[1]\n",
        "\n",
        "    for i in range(len(x)):\n",
        "\n",
        "      out =  qcircuit(params[0],X=x[i])+bias\n",
        "\n",
        "      loss.append((y[i]-out)**2)\n",
        "    weights = compute_sample_weight('balanced',y)\n",
        "    s = 0\n",
        "    for x, y in zip(loss, weights):\n",
        "      s += x * y\n",
        "\n",
        "    return s/sum(weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsYDfcPmxvhA",
        "colab_type": "code",
        "outputId": "e417f8d7-d0e9-4688-a48b-cf1ba5214e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "np.random.seed(0)\n",
        "weights = qml.init.strong_ent_layers_uniform(n_layers=6,n_wires=7,high=1,seed=3)\n",
        "control_weights = np.random.uniform(low=-0.0001,high=.0001,size=(1))\n",
        "params = [weights,control_weights]\n",
        "params"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[0.5507979 , 0.70814782, 0.29090474],\n",
              "         [0.51082761, 0.89294695, 0.89629309],\n",
              "         [0.12558531, 0.20724288, 0.0514672 ],\n",
              "         [0.44080984, 0.02987621, 0.45683322],\n",
              "         [0.64914405, 0.27848728, 0.6762549 ],\n",
              "         [0.59086282, 0.02398188, 0.55885409],\n",
              "         [0.25925245, 0.4151012 , 0.28352508]],\n",
              " \n",
              "        [[0.69313792, 0.44045372, 0.15686774],\n",
              "         [0.54464902, 0.78031476, 0.30636353],\n",
              "         [0.22195788, 0.38797126, 0.93638365],\n",
              "         [0.97599542, 0.67238368, 0.90283411],\n",
              "         [0.84575087, 0.37799404, 0.09221701],\n",
              "         [0.6534109 , 0.55784076, 0.36156476],\n",
              "         [0.2250545 , 0.40651992, 0.46894025]],\n",
              " \n",
              "        [[0.26923558, 0.29179277, 0.4576864 ],\n",
              "         [0.86053391, 0.5862529 , 0.28348786],\n",
              "         [0.27797751, 0.45462208, 0.20541034],\n",
              "         [0.20137871, 0.51403506, 0.08722937],\n",
              "         [0.48358553, 0.36217621, 0.70768662],\n",
              "         [0.74674622, 0.69109292, 0.68918041],\n",
              "         [0.37360012, 0.6681348 , 0.33984866]],\n",
              " \n",
              "        [[0.57279387, 0.32580716, 0.44514505],\n",
              "         [0.06152893, 0.24267542, 0.97160261],\n",
              "         [0.2305842 , 0.69147751, 0.65047686],\n",
              "         [0.72393914, 0.47508861, 0.59666377],\n",
              "         [0.06696942, 0.07256214, 0.19897603],\n",
              "         [0.151861  , 0.10010434, 0.12929386],\n",
              "         [0.55327773, 0.18781482, 0.95210124]],\n",
              " \n",
              "        [[0.68161178, 0.54101967, 0.7071806 ],\n",
              "         [0.26388667, 0.92672568, 0.83919306],\n",
              "         [0.7263195 , 0.48023996, 0.84210319],\n",
              "         [0.74475232, 0.66032591, 0.91397527],\n",
              "         [0.63366556, 0.36594058, 0.55284457],\n",
              "         [0.19638058, 0.1920723 , 0.72566962],\n",
              "         [0.7849367 , 0.97209836, 0.85097142]],\n",
              " \n",
              "        [[0.54359433, 0.08979087, 0.48887324],\n",
              "         [0.92793635, 0.7876182 , 0.48509423],\n",
              "         [0.45527936, 0.21798577, 0.17721338],\n",
              "         [0.07362367, 0.89239319, 0.64017662],\n",
              "         [0.14333232, 0.41412692, 0.04910892],\n",
              "         [0.20937335, 0.73070812, 0.65112277],\n",
              "         [0.4789783 , 0.27478051, 0.65222313]]]), array([9.12899023e-05])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvtqdl3oyr4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_minibatches(inputs, targets, batch_size):\n",
        "    \"\"\"\n",
        "    A generator for batches of the input data\n",
        "\n",
        "    Args:\n",
        "        inputs (array[float]): input data\n",
        "        targets (array[float]): targets\n",
        "\n",
        "    Returns:\n",
        "        inputs (array[float]): one batch of input data of length `batch_size`\n",
        "        targets (array[float]): one batch of targets of length `batch_size`\n",
        "    \"\"\"\n",
        "    for id, start_idx in enumerate(range(0, inputs.shape[0] - batch_size + 1, batch_size)):\n",
        "        idxs = slice(start_idx, start_idx + batch_size)\n",
        "        yield id,inputs[idxs], targets[idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqkZ21Fx9p0",
        "colab_type": "code",
        "outputId": "adada9a7-13a4-4cb1-8e1b-93707cec37e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 1200\n",
        "batch_size = 25\n",
        "from pennylane.optimize import NesterovMomentumOptimizer as no\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "#opt = AdamOptimizer(learning_rate)\n",
        "\n",
        "opt = no(learning_rate)\n",
        "opt.reset()\n",
        "\n",
        "grads = []\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "for it in range(epochs):\n",
        "    final = []\n",
        "    prob = []\n",
        "    X_train_1,y_train_1 = shuffle(X_train,y_train)\n",
        "    X_test_1,y_test_1 = shuffle(X_test,y_test)\n",
        "\n",
        "    for id,Xbatch, ybatch in iterate_minibatches(X_train_1, y_train_1, batch_size=batch_size):\n",
        "        if id == 1:\n",
        "            break\n",
        "        params = opt.step(lambda v: cost(v, Xbatch, ybatch), params)\n",
        "#        loss = cost(params, X_test, y_test, state_labels)\n",
        "        \n",
        "        grads.append(params)\n",
        "        \n",
        "    if it % 1 == 0:\n",
        "      #predictions = [variational_classifier(params, x) for x in X_test]\n",
        "\n",
        "      #predictions = [-1 if (np.sign(i) == -1)  else i for i in predictions]\n",
        " #     for i in range(len(X_test)):\n",
        "#        res = qcircuit(params,X=X_test[i],y=y_test[i])\n",
        "  #      if y_test[i] == 2 and np.sign(res) ==-1:\n",
        "   #       final.append()\n",
        "\n",
        "    #  loss = accuracy_score(y_test,predictions)\n",
        "      test_loss = cost(params, X_test, y_test)\n",
        "#        loss = cost(params, X_test, y_test, state_labels)\n",
        "        #predictions = [np.sign(variational_classifier(params, x=x)) for x in X_test]\n",
        "        #loss = accuracy_score(y_test,predictions)\n",
        "      \n",
        "      print('test accuracy = ',test_loss, \" | \",\"epoch: \", it+1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy =  [0.97548368]  |  epoch:  1\n",
            "test accuracy =  [0.93808834]  |  epoch:  2\n",
            "test accuracy =  [0.89372963]  |  epoch:  3\n",
            "test accuracy =  [0.84744184]  |  epoch:  4\n",
            "test accuracy =  [0.80310297]  |  epoch:  5\n",
            "test accuracy =  [0.76483756]  |  epoch:  6\n",
            "test accuracy =  [0.73231219]  |  epoch:  7\n",
            "test accuracy =  [0.70433238]  |  epoch:  8\n",
            "test accuracy =  [0.67825435]  |  epoch:  9\n",
            "test accuracy =  [0.65387167]  |  epoch:  10\n",
            "test accuracy =  [0.63026455]  |  epoch:  11\n",
            "test accuracy =  [0.60772851]  |  epoch:  12\n",
            "test accuracy =  [0.58785215]  |  epoch:  13\n",
            "test accuracy =  [0.57078943]  |  epoch:  14\n",
            "test accuracy =  [0.55669051]  |  epoch:  15\n",
            "test accuracy =  [0.5455617]  |  epoch:  16\n",
            "test accuracy =  [0.53705242]  |  epoch:  17\n",
            "test accuracy =  [0.5300163]  |  epoch:  18\n",
            "test accuracy =  [0.52454971]  |  epoch:  19\n",
            "test accuracy =  [0.51976112]  |  epoch:  20\n",
            "test accuracy =  [0.5156373]  |  epoch:  21\n",
            "test accuracy =  [0.51168409]  |  epoch:  22\n",
            "test accuracy =  [0.50744213]  |  epoch:  23\n",
            "test accuracy =  [0.50203115]  |  epoch:  24\n",
            "test accuracy =  [0.4957181]  |  epoch:  25\n",
            "test accuracy =  [0.48896334]  |  epoch:  26\n",
            "test accuracy =  [0.4822051]  |  epoch:  27\n",
            "test accuracy =  [0.47558277]  |  epoch:  28\n",
            "test accuracy =  [0.46922229]  |  epoch:  29\n",
            "test accuracy =  [0.46304043]  |  epoch:  30\n",
            "test accuracy =  [0.45747086]  |  epoch:  31\n",
            "test accuracy =  [0.45271033]  |  epoch:  32\n",
            "test accuracy =  [0.44825161]  |  epoch:  33\n",
            "test accuracy =  [0.44444804]  |  epoch:  34\n",
            "test accuracy =  [0.44066563]  |  epoch:  35\n",
            "test accuracy =  [0.43668095]  |  epoch:  36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-c01ea1327eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mybatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#        loss = cost(params, X_test, y_test, state_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/optimize/gradient_descent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, objective_fn, x, grad_fn)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \"\"\"\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/optimize/nesterov_momentum.py\u001b[0m in \u001b[0;36mcompute_grad\u001b[0;34m(self, objective_fn, x, grad_fn)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# default is autograd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     28\u001b[0m                         \"Try jacobian, elementwise_grad or holomorphic_grad.\")\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \"VJP of {} wrt argnum 0 not defined\".format(fun.__name__))\n\u001b[1;32m     66\u001b[0m             \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjpfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0margnum_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mgradient_product\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \"\"\"\n\u001b[1;32m   1240\u001b[0m         \u001b[0;31m# Jacobian matrix of the circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjac\u001b[0m  \u001b[0;31m# numpy treats 0d arrays as scalars, hence @ cannot be used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(self, params, which, method, h, order, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pd_analytic_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pd_analytic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpar_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pd_finite_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36m_pd_analytic\u001b[0;34m(self, params, idx, force_order2, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;31m# basic analytic method, for discrete gates and gaussian CV gates succeeded by order-1 observables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0;31m# evaluate the circuit in two points with shifted parameter values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_p1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcircuit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_p2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcircuit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0mpd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mcheck_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_deps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, queue, observables, parameters)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/operation.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mtemp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pennylane/utils.py\u001b[0m in \u001b[0;36m_unflatten\u001b[0;34m(flat, model)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mstructure\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Inline the cache checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0msubclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0msubtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/_weakrefset.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pending_removals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHsC024gx-9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(params,x,y,margin):\n",
        "  final = []\n",
        "  prob = []\n",
        "  for i in range(len(x)):\n",
        "    out = qcircuit(params[0],X=x[i])+params[1]\n",
        "    prob.append(out)\n",
        "#    print(out)\n",
        "    #if -margin < out <= margin:\n",
        "    #  final.append(0)\n",
        "    if out < margin:\n",
        "      final.append(-1)\n",
        "    if out > margin:\n",
        "      final.append(1)\n",
        "#  print(final)\n",
        "  return accuracy_score(y,final),prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnvcAea0yCl2",
        "colab_type": "code",
        "outputId": "e13944dd-99ee-4084-a6cf-967857d2eaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "predict(grads[14],X_test,y_test,margin=-0.1),y_test"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1.0,\n",
              "  [array([-0.22380664]),\n",
              "   array([-0.22116113]),\n",
              "   array([-0.30126537]),\n",
              "   array([0.23917539]),\n",
              "   array([-0.31754225]),\n",
              "   array([-0.37722629]),\n",
              "   array([0.29926922]),\n",
              "   array([0.11420272]),\n",
              "   array([0.26063584]),\n",
              "   array([-0.25591998]),\n",
              "   array([-0.34262169]),\n",
              "   array([0.28932533]),\n",
              "   array([0.26559402]),\n",
              "   array([0.32076576]),\n",
              "   array([0.22833583]),\n",
              "   array([-0.13998179]),\n",
              "   array([0.30538435]),\n",
              "   array([-0.29778336]),\n",
              "   array([-0.23778385]),\n",
              "   array([-0.20183471]),\n",
              "   array([-0.26783934]),\n",
              "   array([0.09981158]),\n",
              "   array([0.17459887]),\n",
              "   array([-0.27013575]),\n",
              "   array([0.07243808]),\n",
              "   array([-0.18349443]),\n",
              "   array([0.25448586]),\n",
              "   array([-0.27142048]),\n",
              "   array([0.3518442]),\n",
              "   array([0.29784298]),\n",
              "   array([0.17096639]),\n",
              "   array([-0.40620454]),\n",
              "   array([-0.26825863]),\n",
              "   array([-0.28908245]),\n",
              "   array([0.3676674]),\n",
              "   array([0.29239058])]),\n",
              " array([-1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1, -1,  1,\n",
              "        -1, -1, -1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1, -1,\n",
              "         1,  1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPmAA3dEWKE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "ea285609-429a-4e8f-b20c-3813f1384acb"
      },
      "source": [
        "params"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[ 0.65916659,  0.75269909,  0.462421  ],\n",
              "         [ 0.79562387,  0.67706819,  1.09141816],\n",
              "         [ 0.04269267,  0.01407959,  0.00530049],\n",
              "         [ 0.50310918, -0.03199938,  0.52721615],\n",
              "         [ 0.7985506 , -0.08636548,  0.82500634],\n",
              "         [ 0.4203359 , -0.02018885,  0.4194102 ],\n",
              "         [ 0.17873786,  0.88623972,  0.24192472]],\n",
              " \n",
              "        [[ 1.01789658,  0.64067963, -0.04729443],\n",
              "         [ 0.17989108,  0.46320836,  0.4830478 ],\n",
              "         [-0.02629961,  0.60559014,  1.31509806],\n",
              "         [ 1.31417028,  0.87281993,  0.8555992 ],\n",
              "         [ 1.18587069,  0.00936877,  0.26065989],\n",
              "         [ 0.9395481 ,  0.49657997,  0.32993579],\n",
              "         [ 0.47093586,  0.08285624,  0.5310718 ]],\n",
              " \n",
              "        [[ 0.20126419,  0.7434978 ,  1.00450437],\n",
              "         [ 0.76657152,  0.61427208,  0.26490833],\n",
              "         [ 0.38736055,  0.6243423 ,  0.47433956],\n",
              "         [ 0.2810925 ,  1.25328174,  0.3352466 ],\n",
              "         [ 0.48472553,  0.25216341,  0.70426291],\n",
              "         [ 0.66765944,  0.65393333,  0.91235539],\n",
              "         [ 0.50523032,  0.810263  ,  0.06566814]],\n",
              " \n",
              "        [[ 0.97143235,  0.68252418,  0.43119681],\n",
              "         [ 0.23731165,  0.75438906,  0.89493085],\n",
              "         [ 0.69302771,  0.33505967,  0.89581731],\n",
              "         [ 0.81676554,  0.059207  ,  0.82047136],\n",
              "         [-0.25142847, -0.05441096, -0.16154615],\n",
              "         [ 0.37313632,  0.11412702,  0.51554717],\n",
              "         [ 0.28134505,  0.4016569 ,  1.18759681]],\n",
              " \n",
              "        [[ 0.87141036,  0.90389731,  0.67892273],\n",
              "         [ 0.66470072,  0.94410509,  0.91534594],\n",
              "         [ 0.7333361 ,  0.31062673,  0.84210319],\n",
              "         [ 0.78277833,  0.22881435,  0.91397527],\n",
              "         [ 0.63366556,  0.36594058,  0.55284457],\n",
              "         [ 0.05187618,  0.21231781,  0.57537572],\n",
              "         [ 0.88146754,  1.14351279,  0.84323875]],\n",
              " \n",
              "        [[ 0.52522546,  0.06217488,  0.48887324],\n",
              "         [ 0.61275318,  0.75695069,  0.48509423],\n",
              "         [ 0.45527936,  0.21798577,  0.17721338],\n",
              "         [ 0.07362367,  0.89239319,  0.64017662],\n",
              "         [ 0.14333232,  0.41412692,  0.04910892],\n",
              "         [ 0.20937335,  0.73070812,  0.65112277],\n",
              "         [ 0.4789783 ,  0.27478051,  0.65222313]]]), array([0.06837492])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku33upXOKfNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}